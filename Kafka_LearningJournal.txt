1.Kafka Inaugural                       (4 Minutes )     (06-DEC-2019)
2.Kafka 1.0 Update						(2 Minutes )	 (06-DEC-2019)
3.Introduction							(7 Minutes )	 (06-DEC-2019)
4.Core Concepts							(13 Minutes)	 (08-DEC-2019)    (Done)
5.Installing Kafka In Windows			(6 Minutes )	 (26-DEC-2019)	  (Done)
6.Kafka Demo							(9 Minutes )	 (06-DEC-2019)	  
7.Fault Tolerance						(12 Minutes)	 (07-DEC-2019)
8.Broker Configuration					(6 Minutes )	 (07-DEC-2019)
9.Compile Kafka Code					(4 Minutes )	 (07-DEC-2019)
10.Producer API							(12 Minutes)	 (07-DEC-2019)
11.Producer WorkFlow					(6 Minutes )     (07-DEC-2019)
12.CallBack and Acknowledgment			(8 Minutes )     (08-DEC-2019)
13.Custom Partitioner					(13 Minutes)     (08-DEC-2019)
14.Custom Serialize						(11 Minutes)     (08-DEC-2019)
15.Producer Configuration				(11 Minutes)     (08-DEC-2019)
16.Consumer Groups						(9 Minutes )     (08-DEC-2019)
17.Creating Customer					(8 Minutes )     (09-DEC-2019)
18.OffSet Management					(10 Minutes)     (09-DEC-2019) 
19.Re balance Listener					(11 Minutes)     (09-DEC-2019)
20.Exactly Once Processing				(14 Minutes)     (09-DEC-2019)
21.Schema Evolution Part 1				(16 Minutes)     (10-DEC-2019)
22.Schema Evolution Part 2				(10 Minutes)	 (10-DEC-2019)
23.Finale								(2 Minutes )     (10-DEC-2019)
24.Master Class							(3 Minutes )     (11-DEC-2019)
25.Scaling Kafka Producer				(17 Minutes)     (11-DEC-2019)
26.Stream Processing Application		(9 Minutes )     (11-DEC-2019)

***************************************************** 3.Introduction  **************************************************


***************************************************** 4.Core Concepts **************************************************

Producer :
----------
Producer is an Application that sends messages to Kafka.
Some people will call it as Data.
Here message can also be called as Message Record.
Message can be small to medium size piece of Data.
Message can have different meaning or schema for us but for Kafka it is simple Array of Bytes.
For example If i want to send a file to Kafka I will create a Producer Application and send each line of the File as message.
In this case a Message is one line of text for uS but for Kafka it is just an Array of Bytes.
Similarly if i want to send all the records of a Table i will send each row as Message.
If i want to send the result of a Query to Kafka ,I will create a Producer Application and fire a Query against Database,collect the result and start sending each row as a message.
If we want to send some data to Kafka we have to create a Producer Application 
We also get a ready made Producer that fits our purpose.

Consumer :
----------
Consumer is again an Application that receives the data.
If Producers are sending the data they are sending the data to some one.
Consumers are the Recipient.
Producers don't send the data to the Recipient Address and sends the data to the Kafka Server.
Any one who is interested in this data can come forward and get the data from the Kafka Server.
An Application that request data from a Kafka Server is a Consumer.
Consumer Can request the data sent by any Producer provided that they have permissions to read It.
Consumer Application will receive some lines from the Kafka Server.
It will process them and again keep requesting for some more data.
Here Kafka will give new messages to the Consumer as long as new messages are coming from the Kafka Producer.

Broker :
--------
Broker is a Kafka Server.
Kafka Server acts as a Message Broker between the Kafka Producer and Consumer Application.
Producer and Consumer Application don't interact directly and use Kafka Server as an agent to exchange the data between the Applications.

Cluster :
---------
Cluster is a group of systems acting together for a common purpose.
Since Kafka is a Distributed System Cluster has a same meaning for Kafka.
Cluster is a group of systems each executing one instance of Kafka Broker.

Topic :
-------
Producer sends the data to the Kafka Broker.
Consumer gets the data from Kafka Broker.But the question is which data the Consumer has to get.
Here Broker is collecting data from multiple Producers.which one do you want.
Consumer ask the data of Producer ABC.
Here Producer ABC is pushing 3 different type of records.
Then Consumer asks the sales data.
The Broker says that 2 more Producer are sending sales data.
Here we need to have some identification mechanism.
There comes the idea of Topic.

Topic is an arbitrary name given to a DataSet i.e unique name for Data Stream.

For example we create a Topic called Global Orders.
Every Point of sale may have a Producer.
Each of them send their order details as a message to a single Topic named Global Orders.
Consumers interested in Order can subscribe the same Topic i.e Global Orders.


Partitions :
------------
Broker stores the data in a Topic.
If the data is huge and it may be larger than the storage capacity of Single Computer,
In that case Broker may have a challenge of storing  the data.
One of the solution is to break the data and distribute it to multiple computers.
Kafka is a Distributed System that runs on Cluster of Kafka Servers.
Kafka can break the Topic into Partitions and store one Partition in One Computer.
How Kafka will decide the number of Partitions.
Some Topics may be very large and some Topics may be small.
Here we have to take the decision i.e 
When we create a Topic we decide the number of Partitions and Kafka Broker will create the number of Partitions.
Every Partition Sits on a Single Machine.

OffSet :
--------
It is a Sequence Number of a message in a Partition.
This number is assigned to a Message as soon as message arrives in the Partition.
These numbers once assigned they never change i.e. They are Immutable.
Kafka stores the message in the Order of Arrival within the Partition.
First Message gets an Offset 0,Next Message gets an Offset 1 and  so on.
There is no Global Offset across Partitions.
Offset are local to the Partition.
If we want to locate a message we should know 3 things.
Topic Name,Partition Number and Offset Number.


Consumer Group :
----------------
Many Consumers form a group to share the work.
We can consider as one large task and has to be divided among Multiple People.
So we create a group and members of the group can share the work.
For example we have a retail chain and in every store they are few billing counters.
We want to bring all of the invoices from every billing counter to the Data Center.
We use Kafka to transport data from billing location to the Data Center.
First thing we need to do is create a Producer at every billing location.
These Producers will sent the bills as a message to Kafka Topic.
The next thing we might want to create a Consumer.
Consumer will read the data from Kafka Topic and write them into Data Center.
But the problem is Scalability.
Here hundreds of Producers are pushing the data to a Single Topic.
Then how the single Consumer can handle the Volume and Velocity.
Here we have to create a large Kafka Cluster and partition the Topic.
Here Topic is Partitioned and Distributed across the Cluster.
Several Brokers are sharing the workload to receive and store data.
Form the source side we have many Producers and several Brokers to share the work load.
From the destination side we have a Single Consumer.
Here comes the Consumer Group.
We create a Consumer Group and start executing multiple Consumers and tell them to divide the work.
How do we divide the work to the Consumers.
For example we have 600 Partitions and each Consumer can handle the 6 Partitions.
If this is not sufficient create some more Consumers in the same Group.
It can go up to 600 Consumers.
Maximum Number of Consumers in group is Total Number of Partitions in the Topic.
Kafka does not allow more than 2 Consumers to read the data from the same Partition simultaneously.
This restriction is necessary to avoid double reading of Records.

***************************************************** 5.Installing Kafka In Windows *****************************************************

PreRequisite are 
JDK 1.8
Single Node Kafka Cluster
Build Tool Like Maven3
IDE Such as Eclipse or IntelliJ
Download Single Node Kafka Cluster

http://mirrors.estointernet.in/apache/kafka/2.4.0/kafka_2.12-2.4.0.tgz

Copy the Kafka Folder 

D:\Software\kafka_2.12-2.4.0 and Make it as Kafka Home

Create a Zookeper DOrectory and change in the zookeeper.properties 
dataDir=D:\Software\kafka_2.12-2.4.0\zookeeper_data

Kafka Server Configuration i.e Open the server.properties File and Change The Path of Log Files.
log.dirs=D:\KafkaLogs

The Other Configuration in server.properties are 
offsets.topic.num.partitions=1
min.insync.replicas=1
default.replication.factor=1

To Run the Single Node Cluster on Windows copy the Path in Environment Variable i.e 
D:\Software\kafka_2.12-2.4.0\bin\windows in System variable Path
To Run the Kafka,Kafka First We Need to Start the Zookeeper 
--> zookeeper-server-start.bat D:\Software\kafka_2.12-2.4.0\config\zookeeper.properties
To Start the Kafka Server 
--> kafka-server-start.bat D:\Software\kafka_2.12-2.4.0\config\server.properties

Now the Zookeeper and Kafka are Running on Separate Windows.
If We Want to Shut Down ctrl+c 
To test the Kafka Server Start the New Window.
Execute The Zookeeper Shell and ask them for the List of Broker Ids
--> zookeeper-shell.bat localhost:2181 ls /brokers/ids
To Create a Kafka Topic in Windows :
--> kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
To Create a Producer 
--> kafka-console-producer.bat --broker-list localhost:9092 --topic test
Enter the Messages
To Create a Consumer 
--> kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from beginning

