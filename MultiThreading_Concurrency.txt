Defog Tech :
************
1.Concurrency vs Parallelism						[08-JAN-2020]  (Done)
2.Java Memory Model									[15-JAN-2020]  (Happens Before Pending)
3.ExecutorService Introduction						[20-JAN-2020]  (Done)
3.ExecutorService Pool Types						[21-JAN-2020]  (Single ThreadExecutor Pending)
3.ExecutorService LIfe Cycle						[21-JAN-2020]  (Done)
3.ExecutorService Callable/Future					[27-JAN-2020]  (Done)
4.Fork JoinPool										[27-JAN-2020]  (Done)
5.Java Asynchronous Programming						[28-JAN-2020]  (Done)
6.Completable Future								[28-JAN-2020]  (Done)

7.Lock Condition Class								[05-JAN-2020]  ()
8.Reentrant Lock									[05-JAN-2020]  ()
9.ReadWrite Lock									[05-JAN-2020]  ()
10.Synchronous Queue								[05-JAN-2020]  ()
11.ThreadLocal										[05-JAN-2020]  ()

12.Volatile vs Atomic Integer						[05-JAN-2020]  ()
13.Adder and Accumulator Classes					[05-JAN-2020]  ()
14.Phaser vs CountDownLatch vs Cyclic Barrier		[05-JAN-2020]  ()
15.Semaphore in Java Concurrency					[05-JAN-2020]  ()
16.Exchanger Class									[05-JAN-2020]  ()
17.Guava Library									[05-JAN-2020]  ()


******************************************** 1.Concurrency vs Parallelism ************************************************************


Parallelism :
-------------
Let us Consider an Example
Here Two Threads are Executing In Parallel and One Method.

	public static void main(String[] args) 
	{
		
		new Thread(new Runnable() {
			public void run() {				--> Task One
				processTax();
			}
		}) {
		}.start();
		
		
		new Thread(new Runnable() {
			public void run() {				--> Task Two
				processTax();
			}
		}) {
		}.start();

		hevayCalculations();				--> Task Three
	}

Here Task One and Task Two runs on Two Different Threads and Task Three runs on the Main Thread.
If we Run this Program on a Quad Core Processor i.e there are 4 Cores in a Processor,
Then we can Run These Tasks in Parallel.
In OS We have a Component Called Scheduler which is Responsible to Schedule these Threads on to these CPU Processor.

Task One  Runs on Core 1
Task Two  Runs on Core 2
Task Three  Runs on Core 3
Task Four  Runs on Core 4

Here All these Task will Run in Separate Cores in Parallel.
Parallelism is about doing lot of things at once so that we can speed up Performance.

We can also Change the Above Code by Using ExecutorService.
Using ExecutorService Fixed Thread Pool.

		ExecutorService executorService=Executors.newFixedThreadPool(4);
		executorService.submit(()-> processTax());
		executorService.submit(()-> processTax());
		
In Java To Enable Parallelism We Can Use Raw Threads(Implementing Runnable or Callable Interface) or We can use The Concept of Thread Pool.
Even in Thread Pool It Can be 

1.ExecutorService
2.ForkJoin Pool
3.Custom Thread Pools (Used By Web Servers)

Here We Need to Ensure that the CPU has More than One Core So that We can run the Threads In Parallel.

Concurrency :
-------------
Consider the Scenario for Booking a Ticket.

		new Thread(() -> {
			if(ticketsAvailale>0)
			{
				bookTicket();				-->  Task Accessing Shared Variable
				ticketsAvailale--;
			}
			
		}).start();
		
		new Thread(() -> {
			if(ticketsAvailale>0)
			{
				bookTicket();			 	-->  Task Accessing Shared Variable
				ticketsAvailale--;
			}
			
		}).start();
		
		Thread.sleep(500);
		
Here Each Tasks Shares the Common Resource i.e ticketsAvailale Variable.
After Starting Two Threads Put The Main Thread in Sleep For Two Seconds.
Let us Assume that we have a Single Core Processor in CPU and OS Scheduler is Responsible for assigning these Threads to the Processor.
Since CPU has Single Core Processor,Scheduler has to do Time Sharing Between The Threads.
Here The Scheduler Will Schedule the Thread 1 for Few Milli Seconds and Pick Thread 1 out and Keep Thread 2 For Few Mill Seconds.
This Concept is Called Interleaving of Threads.
How Much Time Scheduler Assigns to the Thread is Non Deterministic and Depends on Many Factors.
Here it Might Possible That Thread 1 Accomplishes all the Task within Time.
In Worst Scenario If The Thread has Not Accomplished the Task then there is Mismatch in Processing.
This is also the Case with MultiCore Processor.

To resolve the Issue we use the Concept Called Lock.
Thread One will Acquire the Lock,Completes the Task and Updates the Shared Variable and Release the Task.
Here Multiple Threads are Coordinating Between Each Other Using a Single Lock.
This Scenario is Called Concurrency.

Concurrency is about Dealing lot of things Once.
Concurrency is Applied When we Have a Shared Resource that has to be Accessed or Updated or Multiple Threads needs to Coordinate.

In Java we Have Lot of Tools to Deal With Concurrency.

1.Locks /Synchronized
2.Atomic Classes
3.Concurrent Data Structures (ConcurrentHashMap.Blocking Queue)
4.Completable Future
5.CountDownLatch / Phaser / CyclicBinder / Semaphore etc.

Concurrency  + Parallelism  :
-----------------------------
Split the Sequential flow into independent Components.
Use Thread / Thread Pool to Parallelize these Components.
Whenever a Shared Resource has to be updated across the Components or Multiple Threads needs to be Coordinate Use Concurrency Tools to Manage.


******************************************** 2.Java Memory Model ************************************************************

Java Memory Model is a Specification which Guarantees the Visibility of Fields when we have re Ordering of Instructions.
Java Memory Model Enforces that all the JVM has to implement these set of Rules so that Program Runs in the Same Manner. 

1.Order of Execution
2.Field Visibility
3.Happens Before

1.Out of Order Execution :
--------------------------
When we Write a Program and in General it is a Series of Statements.
We Expect that It will Run in the Same order as we have Written.
But is Completely Possible that the Compiler or JVM or CPU will Change the Order of Instructions to drive Some Performance out of it.
This is Done in a Way that the Program Semantics Remains Same and Output will Not Change.

Consider the Scenario 

a=3;
b=1;
a=+1;

Actual Conversion look Like 

Load a
Set to 3
Store a

Load b
Set to 1
Store b

Load a
Set to 4
Store a

Here we are Loading a Twice and 
one Performance Improvement could be incrementing the Value would be before setting the Value.

Load a
set to 3
set to 4
Store a

Load b
Set to 1
Store b

 
2.Field Visibility :
--------------------
Field Visibility is only applicable in terms of MultiThreaded Applications and also Called Concurrent Programming .

A.If we have a Quad Core Processor Machine Generally that have 4 Cores and each core has Set of Registers.
B.Registers are Nothing but a Memory Area which is very Small and is within the Core,
  Stores the Value in the Register and it is Faster to retrieve the value from the Register.
C.we Have L1 Cache for each Core i.e Nothing but Memory Area Set a Side For Each Core.
D.We Have L2 Cache which could be Shared between Shared L1 Cache.
E.We Have L3 Cache which could be Shared between Shared L2 Cache.
F.We Have RAM which could be Shared across Cores.

Consider the Example :

			int x=0;
	
			public void writerThread()
			{
				x=1;
			}
			
			public void readerThread()
			{
				int reader=x;
			}			

Here Initially the Value is Stored in the Shared Cache.
Consider Thread T1 Calls the WriterThread() and Thread T2 Calls the ReaderThread().
Thread T1 sits into the Core 1 and Thread T2 Sits into the Core 2.
When the Thread T1  Executes the writerThread(), Value is incremented and updated in the Local Cache of Thread T1.
Similarly When the Thread T2 executes the readerThread(),It Wont get the Updated Value because it is not Updated in the Shared Cache.
It is Completely Possible that x=1 is Never Pushed into the Shared Cache.
This issue is Called Field Visibility Issue.

We Can Resolve the Issue by Using volatile Key Word.
If the Variable is volatile,then JVM Ensures that Changes in the Local Cache will be flushed to the Shared Cache 
so that the Remaining Threads will get The updated Value.

3.Happens Before :
------------------




******************************************** 3.ExecutorService ****************************************************************************************

Introduction :
--------------
In Java it is Easy to run a Piece of Code or Method Asynchronously by using Threads.
Consider we have a Main Method which runs on Main Thread and we can run the Task on the Separate Thread.
Create a Task and the Task has to implement Runnable Interface and override its run() and keep the Method that we want to execute Asynchronously.

				public static void main(String[] args) 
				{
					Thread thread=new Thread(new Task());
					thread.start();
					System.out.println(Thread.currentThread().getName());
				}
				
				static class Task implements Runnable
				{
					public void run()
					{
						System.out.println(Thread.currentThread().getName());
					}
				}

Here the Flow will be Main Thread will perform these operation from top to bottom and
at Certain Point of Time It will call start() Method and it will Create a Thread with Name thread-0.
thread-0 will do its own Operations and once the Operation is Done thread will be killed automatically.
Here Main Thread Continues its execution.

In the Above Example we are Creating Single Task.
Consider the Scenario where we want to execute 10 Tasks and in this Case we need to Create Thread Using For Loop.

			for(int i=0;i<=10;i++)
			{
				Thread thread10=new Thread(new Task());
				thread10.start();
				System.out.println(Thread.currentThread().getName());
			}

Here Each Time It will Create a New Thread with the New Instance of the Task and that will be executed independently.
Here the Flow starts from Main Thread and after Certain Point of time For Loop is getting executed.
Here Each time new Thread is being created and will be executed asynchronously.
once the task is executed successfully thread will be killed automatically.

Problem with this Scenario is in Java One Thread is equal to One Operating System Thread.
If we run the For loop 1000 Times it will Create 1000 Threads and Creating a Thread is an Extensive Operation.

If we want Fixed Number of Threads to be Created upfront or can be Called as Thread Pool and then submit the Task to the Thread Pool,
Then we use ExecutorService.

			ExecutorService executorService=Executors.newFixedThreadPool(10);
			for(int i=0;i<=1000;i++)
			{
				executorService.execute(new Task());
			}

Here Instead of Creating new Threads every time,Here We are creating threads upfront and submitting the task to the threads which are created already.
Thread Pool Internally uses Blocking Queue and Keeps Storing all the Tasks which are Submitted.
Threads in the Thread Pool will perform Two Steps i.e fetch the Next Task from the Queue and execute it.
Since all the 10 Threads are executing Simultaneously to get the Task from the Queue,
Queue has to handle Concurrent Modifications and Should be Thread Safe.
To Resolve this issue Queue in the Thread Pool is implemented using Blocking Queue.

Ideal Pool Size :
-----------------
If we have Created More Number of Threads i.e 1000 ,These Threads will be executed based on Time Slicing.
Solution is depends on the Type of Task we want to execute.

If the Task is CPU Intensive Operation i.e if the Task is Taking time to Execute 
then the Ideal Pool Size will be the Same as CPU Core Size.
Here all the Threads will be executed in the CPU cores independently and none of the Threads are Waiting for anything.
Consider the Scenario where other applications are running on the CPU and Mostly We wont get all the CPU Cores.

			int processors=Runtime.getRuntime().availableProcessors();
			ExecutorService execService=Executors.newFixedThreadPool(processors);
			for(int i=0;i<=1000;i++)
			{
				executorService.execute(new CPUProcessor());
			}
			
If The Task is an I/O Operation i.e It May be a call to the database or call to an External Service then we need to create a Thread Pool with maximum Size.
Because If any of the Thread is time Consuming and After Certain time No Threads will be available to pick up the Task from the Queue.
Here Pool Size will be the Same as the Number of Tasks we are Submitting.
Too Many Threads will increase the Memory Consumption  too.
 
			ExecutorService execService=Executors.newFixedThreadPool(1000);
			for(int i=0;i<=1000;i++)
			{
				executorService.execute(new CPUProcessor());
			}
			
Fixed Thread Pool :
-------------------
Here Fixed Number of Threads will be Created upfront and keep Submitting the Task to Execute.
All the Task we Submit are Stored inside the Particular Queue and the Queue is Blocking Queue to Handle Concurrent Operations
All these Threads will fetch the Task from the Queue one after the Another.
   
			ExecutorService execService=Executors.newFixedThreadPool(10);
			for(int i=0;i<=1000;i++)
			{
				executorService.execute(new CPUProcessor());
			}
			
Cached Thread Pool :
--------------------
Here we don't have Fixed Number of Thread Pool and we also Don't have Queue that holds the Task that we Submit.
Here Queue is Replaced by Synchronous Queue and has Space for Only Single Item.
When we Submit the Task,Task Will be Stored inside the Synchronous Queue and Search for the Thread which is already Created 
or which Thread is available.
If No Such Thread is available it Will Create a New Thread,add it to the Pool and Newly added Thread will execute the Task.
Cached Thread Pool has  a Mechanism that deletes the Thread once the Thread is idle for 60 Seconds.

			ExecutorService cachedPool=Executors.newCachedThreadPool();
			for(int i=0;i<=1000;i++)
			{
				cachedPool.execute(new CPUProcessor());
			}
 
Scheduled Thread Pool :
-----------------------
1.scheduledPool.schedule() :
----------------------------
scheduledPool can be used for the Tasks to be executed after a Certain Delay.

ExecutorService scheduledPool=Executors.newscheduledThreadPool();
scheduledPool.schedule();
		
2.scheduledPool.scheduleAtFixedRate(10) :
-----------------------------------------
If We want to perform Checks like Security Checks,Logging Checks for every 10 Seconds we use Scheduled Thread Pool.
Here Tasks Keep on executing for every 10 Seconds.

ExecutorService scheduledPool=Executors.newscheduledThreadPool();
scheduledPool.scheduleAtFixedRate(10);

Here It will store all the Tasks in the Queue and This Queue is a Delayed Queue.
In Delayed Queue where Tasks Might not be in Sequence.
The Tasks will be Distributed based on when the Task needs to be Executed i.e Time Interval.

3.scheduledPool.scheduleAtFixedDelay(10) :
-----------------------------------------
If we want to run the Task for every 10 Seconds after the Completion of Previous Task with Delay in Seconds we use
scheduledPool.scheduleAtFixedDelay(10,15);
Consider the Scenario where the Task itself takes 15 Seconds and we cannot say  that run the Task for every 10 Seconds.
So Here in case of scheduleAtFixedDelay() it will Complete the Task that Takes 15 Seconds and after that it will delay for 10 Seconds
and Schedule the next Instance of the Task.

Single ThreadExecutor :
-----------------------


Executor Service Life Cycle Methods :
-------------------------------------

shutDown() :
To shutDown the Thread Pool we Use shutDown().
shutDown() initializes the Executor Service to shutDown the Thread Pool.
It Will Not shutDown the Thread Pool Immediately and wait for the Tasks to be Executed which are stored inside the Blocking Queue.
After Calling the shutDown() it will not accept any Task and throws RejectionExecutionException.

isShutDown() :
To Check whether the shutDown has initiated or Not we use isShutDown().

isTerminated() :
To Check whether the shutDown has Completed we use isTerminated().
This will return true If all the Tasks are Completed which are stored inside the Blocking Queue.

awaitTerminattion(10,milliseconds) :
SomeTimes we don't want to wait till all the Tasks to get Completed.
Terminate the Thread Pool until all the Tasks being Completed or wait until these Milli seconds.
Once the Time is reached Terminate the Thread Pool.

shutDownNow():
will Complete all Tasks which are Running by these Threads and it will not Initiate for the Task to get Execute.
It will Return all those Task which are Stored inside the Blocking Queue.


ExecutorService Callable/Future :
---------------------------------
We Can Submit the Task by Using execute() of ExecutorsService where as we can define a Task by Using Runnable or Callable Interface.
By Using Runnable Interface we can define and Submit The Task and it wont return any Result.
To get the Result Submitted by the Task we use Callable Interface.

		ExecutorService executorService=Executors.newFixedThreadPool(4);
		executorService.execute(new Task());

		class Task implements Runnable 
		{
		@Override
		public void run() {

		}
	}

execute() expects a Runnable Task where as submit() expects a Callable Task.
submit() returns Future Object i.e Thread Pool Provides a Place Holder for the Future Object and Once the Value is returned 
Place Holder is Filled with the New Value.

when we submit the task using submit() of ExecutorsService it will Immediately return the Future Object with Place Holder.
we Can Perform Remaining Operations.
Once the Main Thread Calls the Future Object then the Thread goes into Blocking State.

		ExecutorService executorService1=Executors.newFixedThreadPool(4);
		executorService.submit(new CallableTask());
		System.out.println(Thread.currentThread().getName());
		
		
		class CallableTask implements Callable<String>
		{
		@Override
		public String call() throws Exception 
		{
			return "Srinivas Sankoji";
		}
		
		}

One Way to Resolve the Blocking Operation of get() is use the TimeOut.
get() provides a Overloaded version with Timeout as Parameter.
		
		result.get(12,TimeUnit.MILLISECONDS);//Non Blocking Operation
 
we can Specifically cancel the Task by Using cancel() of ExecutorService.
Thread Pool Immediately cancels the task before Thread Pool has Started Working on it.
If The Task has Started in one or More Thread then cancel() has No Impact.
We Can also Check the Current Status of the Task by using isCancelled() and isDone() of ExecutorService.
 

******************************************** 4.Fork JoinPool ****************************************************************************************

Fork JoinPool is Similar to Executor Service but with Two Differences.
ExecutorService Stores the Task in the Blocking Queue and these Tasks are executed by the Thread Pool which we Have defined while defining the Executor Service.
These Thread Takes the task from the Blocking Queue and executes it until all the tasks are Completed in the Blocking Queue.

1.Fork Join Pool Deals with Task and produces its own Task.
Fork Join Pool Optimize the Problem of Task by Producing Sub Tasks for the Task.

Let us Consider a Task and that is Big Task.
Break down the Task into 3 Sub Tasks and each of them Computed or solved Independently.
Here all the Sub Tasks run in Parallel at once considering we have CPU which has More than one Core.
All the Results are aggregated to provide the Final Result.

Consider the Example of Fibonacci Example.
Fibonacci Number is a Sequence where every Number in the Sequence is a Multiple of Last Two Numbers.

2.Per Thread Queuing  
In case of Fork Join Pool Each Thread has its own Queue and this type of Queue is called Double Ended Queue.
Consider a Thread is executing a Particular Task and when we do Fork i.e split the Task into Multiple Sub Tasks and all those Sub Tasks are Not Stored in the 
Common Queue and they are Stored in its own Double Ended Queue Locally.
Now for the Thread which is Executing the Main Task,It is Easier to pick the Task which is Stored inside the Double Ended Queue.

Now Every Thread which is executed in the Fork Join Pool has its own Doubled Ended Queue to Store all the Sub Tasks that it Creates.
We don't have to Worry about getting the Tasks from the External Queue.
It Keeps Picking the Tasks from the Local Queue and keep executing them.
Since we are Touching our own Queue and we don't have to worry about Synchronization.
Since Threads are Always Busy there won't be any switch between context of Threads.

3.Work Stealing
Consider Two Threads Thread1 and Thread2
Thread1 Produces lot More Sub Tasks than Thread2
At Certain Point of Time Thread2 has No Tasks to Execute i.e its own Dqueue is Empty.
In this Case Thread2 Picks the Task form Thread1 using the Other End of the Queue i.e
Thread 1 Picks the Task from Front where as Thread 2 Picks the Task from Back.


To Execute The Fork Join Pool in an Effective Way
1.Avoid Synchronization
2.Do Not Use Any Shared Variables
3.Do Not Perform any Blocking Operations
4.Pure Functions
5.Isolated Functions

Fork Join Pool has the Same Methods that has Future Interface.
Use Cases of Fork Join Pool are 

1.Sorting
2.Matrix Multiplication
3.Best Move Finder for a Game
4.Tree Traversal


******************************************************** 5.Java Asynchronous Programming	*******************************************************

Most of the Computers today we have More than 1 Core Processor.
Typically a Desktop Computer have 4 Cores and Server may Contain 16 Cores or 32 cores or More.
To take Advantage of these cores we create Multiple Threads in our Application.
We can do that by Using 

new Thread().start()
Thread Pool
Fork join Pool and so on.

Creating too Many Threads in Parallel May cause Some Problems and that is because of How Java Works.
In Java Every Thread we Create is an Operating System Thread or Native Thread or Kernel Thread.
Java itself has Variables For every Thread Like Program Counter,Java Stacks,StackFrames and so on.

For Every Thread,there will be a Corresponding OS Thread and that will consume lot of Memory and 
that Limits the Number of Parallel Threads or Active Threads in JVM(Application that runs on JVM).
We Cannot have thousands of Threads in our Application and that will throw out of Memory Exception and the Program will Shut Down.

Once we have Too Many Threads there are Other Problems that may come out.
Consider we have lot of Threads and in CPU we have 2 Cores.
Every Core will have some Local Cache and Consider Core1 is running the Thread 1.
Local Cache has all the Data which is Required by Thread 1.
If there are Lot of Threads and we need to Schedule some other Threads at Some Point of Time.

If we want to Schedule Thread 3 and for that we Need to Flush the Local Cache which Contains the data related to Thread 1
and Place the Data Related to Thread 3 in the Local Cache.
Here Core 1 will Start executing the Thread 3.

Again If there is Context Switch,Flush the Old Thread Data and add The New Thread Data.
This Scenario is Called ###########Data Locality#########.

If there are lot of Threads,OS or JVM has to manage the Scheduling of Threads which itself takes lot of Time.
The Issue of Having too Many Threads is even More Heighten when  we are Dealing with I/O Operations.

Consider the Main Thread which is performing I/O Operation.
I/O Operation may be a Call to Another MicroService or Database Operation.

When Main Thread Triggers that Particular I/O Operation,then Main Thread will goes into Blocking State
Until The I/O Operation is Completed and Main Thread cannot do anything  else and goes into Waiting State.
Here CPU Cycles are Wasted.
Once the Data is Returned from the I/O Operation Main thread goes into Runnable State and Performs the Remaining Process.

The Problem of Having a Blocking Thread Means It will not perform any Other Operations while the operation is being Completed.

The Ideal Solution is Non Blocking I/O.
Main Thread Trigger the I/O Operation and Immediately Comeback without Taking the Result.
Once the Data is Ready from I/O Operation,then call the Callback Method and will be called by using another Thread.
Here Main Thread keep on Performing Subsequent Operations.

For Loop with Task Defined using ExecutorService will always goes into Blocking State.
Here For Loop goes into Waiting State.

Creating lot Number of  Threads becomes Expensive and Blocking I/O Operations makes limit to Scale the Application.
Here the Solution is Non Blocking I/O and Instead of Synchronous API we Need Asynchronous API.

Asynchronous API is Nothing But Callback and can be achieved by using Completable Future in Java 8.  
For Non Blocking API Java 7 Introduced the Concept of Java NIO and also called as NIO Package.
Servlet 3.1 Onwards the Web Request Becomes Non Blocking.
Spring Web Flux is a Non Blocking API and comes with Push Operation where as Future is a get Operation.

Advantages of Using Asynchronous Programming :  
Efficient CPU Utilization  
Scalability and High Throughput  
No Issue of Data Locality and Less Context Switches 
Reactive  
Live Values 	
Back Pressure  

Issues in Asynchronous Programming :
Hard to Write and Reason About	
CPU Bound Flows	
Hard to Debug and Stack Trace	
Hard to Write Test Cases	
End to End Asynchronous / Non Blocking  Required	

To Achieve Light Weight Threads and Synchronous Programming there is an Upcoming project Coming Soon i.e Java Fibers or Project Loom.

******************************************************** 6.Completable Future *************************************************************

Completable Future is used to Perform Possible Asynchronous Computation and Trigger its Dependent Computations which could also be Asynchronous.

In Java To Perform Non Blocking Operation is Always Easy i.e Create Runnable and run it in Separate Thread.
Once Runnable calls the run() and after the Execution of run() Thread is Destroyed.
If The Task is Expecting the Return Value,then We Use the Callable Interface.We Typically do this by Using ExecutorService.
Here the Task return the Future Object and when we Call get() on the Future Object then Main Thread goes into Blocking State.
Here the Problem gets More Difficult when we have Multiple Tasks.
Consider the Scenario where we have submitted 4 Tasks to the ExecutorService.
Immediately It will return a Future Value with the Place Holders.
Task 3 and Task 4 are Executed Successfully and Task 1 and Task 2 are Still Waiting for the Response because 
Thread Pool does not Guarantee that order of Execution of Tasks.
If we call future.get() and we don't have value for the Task 1 the Main Thread goes into Waiting State.
Here the Problem is even though many Task were Completed and we are Using For Loop to get the Future Object
and For Loop Starts its Iteration with First Element.
Since we don't have value for Task 1 then Main Thread goes into Waiting State.

Consider the Use case :

Fetching Order
Enriching Order
Payment
Dispatch
Send Email

For Order Flow we Have 5 Different Tasks.

If we Use the ExecutorService then we have to Create 5 Tasks and Using Callable and submit it to the ExecutorService.
Here Each Task is Dependent on Another Task and we use future.get() to get the Result and it goes into Blocking State.
If we have For Loop Over the Orders an to Create On Order2,Order3,Order4 Until the Completion of Order1.
Here Main Thread will not Scale Much Further and It is almost Sequential Operation order1 has to be complete before order2.

There are Dependency on order of Execution.
It is Completely Possible that a Thread can do a Payment Process for One Order while Other Thread Performing Enrichment for Another Order.

We have N Number of Threads all doing processing of One Particular Flow.
Within One Flow Tasks are Dependent on Each Other But One Flow is not Dependent on Another Flow.

If We Convert into an Algorithm i.e for N Number of Orders We want to run the Task Once and once Particular Task is Completed,run its Dependent Task and so on.
This has to be Done Completely Independent for Every Task that we Submit.
Don't Care about Thread Pool is Going to Execute those Tasks Internally and here Main Thread does not goes into Blocking State.
This is Exactly Completable Future was Designed for.
Completable Future Provides a Function called supplyAsync() that accepts a Task and has to be executed Asynchronously.
Once the Task has been Executed Successfully give the output to another Task using thenApply()
There is also an Overloaded Method thenApplyAsysnc().In This Case the Thread which is Performing supplyAsync() 
and other Thread will perform the subsequent Operations.
thenApplyAsysnc() can be used if we define our own Thread Pool.
One Thread does not Belongs to Two Different ExecutorService and in This case we use overloaded method of thanApply().
If we don't use any Executor Service Internally it Uses Fork Join Pool to run all the Tasks.
If any of the Operation is Failed exceptionally will be called as a Catch Block.
For Complex Use cases Completable Future is Not Recommended and Prefer RX Java which is Stable and Much More Readable.

*********************************************************************************************************************************************************



  

 
















		





