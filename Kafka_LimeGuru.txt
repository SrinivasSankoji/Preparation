1.Introduction              (27-DEC-2019) (Done)
2.Topics and Partitions		(02-JAN-2020) (Done)
3.Producer					(05-JAN-2020) (Done)
4.Consumer					(17-DEC-2025) (Done)


***************************************************** 1.Introduction *****************************************************

Kafka is a Messaging System.
There are some Systems which produce the data and publish the data to the Messaging System.
There are some Systems which consumes the data.
System which produces the data are called Producers.
System which takes the data are called Brokers.
System which consumes the data is called Consumers.

The System which produces the data can be any Application like Website,Backend Application etc.
Producer can pass the data to another Application which can be a Consumer and here the communication is one to one.

Consider the scenario where there is no Topic.
If the data needs to be consumed by multiple Consumers then producer has to take the responsibility of providing the data to multiple Consumers.
Here Producer can be any Application like Website,Backend Application etc and cannot handle this scenario.

Here comes the Messaging System which acts as a Broker between Producer and Consumer.
Messaging System allows the Producer to push the data and Messaging System is responsible for providing the data to the Consumers.
Here Messaging System also stores the data internally.
In any Messaging System there are Producers,Consumers and Brokers.
Messaging System is also called as Broker.

The other Messaging Systems are JMS,RabitMQ,Active MQ etc are not distributed.
These Messaging Systems are single point of failure.
Kafka provides some features which are not available in other Messaging Systems.

Distributed :
-------------
We have the provision to start the Multiple Kafka Servers i.e. Cluster which acts as a Single Messaging System i.e.
Cluster contains Multiple Brokers.
Whenever any Producer is publishing the data to the Kafka, Kafka internally handles the distribution of data and stores the data into Multiple Brokers inside the Kafka Cluster.
Here the Consumer can access the data from Multiple Brokers inside the Kafka Cluster.

Message Storage System :
------------------------
Whenever any Producer is publishing the data to the Kafka,Kafka internally stores the data until we explicitly mention the retention period.
Here multiple Consumers can still access the data from the Kafka.
In Other Messaging Systems as there is no concept of Storage,Consumers cannot access the past data.

Fault Tolerance :
-----------------
Kafka ensures that the system continues to operate correctly even if one or more component fails.
It is a key aspect of Kafkaâ€™s high availability and durability design.
Here Multiple Brokers are responsible to process the data, store the data and serving the data to the consumer.
If any of the Node goes down, Other Nodes will take care of processing the data.

Real Time Streaming Messaging System :
--------------------------------------
For example we are getting the data continuously from the Producer System.
As Kafka is highly available and distributed,Kafka process the real time data.
Whenever any Message comes to Kafka System,Kafka transforms the data and then provide the data to the Consumer.

UseCases of Kafka :
-------------------
In E-Commerce Application multiple users are browsing the Application.
If we want to improve the User experience we need to provide the solution based on user experience instantly.
We need to stream the User Navigation and publish the data to the Messaging System.
Based on events we can provide the solution to the User.
We can also store the data in Other System like Big Data,Database or another Kafka Topic.
Realtime solutions are helpful in improving the Business.

************************************************** 2.Topics and Partitions ******************************************************

Topic :
-------
Producer will publish the messages to the Kafka Broker and Consumer will consume the messages form Kafka Broker.
There should be some unique mechanism to identify the dataset which is nothing but Topic.
Producer will publish the messages to the Single or Multiple Topics.
Similarly Consumer will consume the messages from Single or Multiple Topics.

Partitions :
------------
Kafka is a Distributed Messaging System.
The messages are stored in a distributed manner and distribution can be achieved by using Partitions.
Whenever we create a Topic we need to create a partitions for that Topic as per requirement.

For example we have created 4 Partitions for a single Topic.
Partition 0 and 1 sits in Broker1
Partition 2 sits in Broker2
Partition 3 sits in Broker3

Whenever we create a Kafka Cluster it internally contains Kafka Servers.
Here each Kafka Server is nothing but Kafka Broker and each Broker contains different Partitions.
Kafka internally looks for the availability for the creation of Partition based on Physical Storage,and also it will make sure the distribution is highly achievable.
Here each Partition sits in the different Broker for highly availability.

Whenever multiple messages are coming to the Topic and how the data is stored internally inside the each Partition of the Topic.

Message M1 sits in the Partition 1
Message M2 sits in the Partition 2
Message M3 sits in the Partition 3
Message M4 sits in the Partition 4
Message M5 sits in the Partition 1
and so on.

Producer will just publish the Messages to the Topic and Kafka internally distributes the messages among different Partitions.

Message Storing in Partition :
------------------------------
Kafka internally creates a Log File in the Physical Storage of each Partition.
All the messages which are coming for a Particular Topic will be committed in the particular Log File of each Partition.
Kafka manages the sequence of the messages in the Log File for the particular Partition using Off Set.
Off Set is a Unique identifier for the particular message.
Offset helps in identifying the messages read by Consumer Program.
Once the Message is read by Consumer Program it will mark as read in the Consumer Program and it won't read the message again.
Here multiple Consumers can read the messages from different Partitions of the Topic because messages are stored inside Log File.

Replication :
-------------
For example message M1 is Stored in the Partition 0 with an OffSet Number.
Replication says Whenever any new message is coming to the particular Partition then that Partition will become the Leader Partition and 
based on the Replication Factor same message will also be stored inside other partition.
The Other Partitions which are storing the same messages are called as Follower Partitions.
Advantage of Follower Partition is that if particular Partition goes Down or Kafka Broker that Contains the Particular Partition goes down,
Then Kafka will convert the Follower Partition as a Leader Partition.
These Partitions will provide the data to the Consumers.
This is how High Availability and Fault Tolerance can be achieved in Kafka.
Replication factor should always be less than or equal to number of brokers.


**************************************************** 3.Producer  *******************************************************************

There are some configurations required for the Producer Application to optimize so that we send the messages in the correct way to the Kafka Server.

A.Reliability :
---------------
Reliability is the most important factor while publishing the messages to the Kafka Broker.
Here we don't want any message to be lost into the middle.
This reliability can be achieved by using ACK Configuration.

ACK 0 
ACK 1
ACK ALL or -1

ACK 0 :
-------
Whenever any Producer Application is publishing the messages to the Topic(Kafka Cluster),
Here Producer Application won't check whether the messages are successfully written to the Topic or Not.
It is Completely dependent on stability of the Kafka Cluster.
Here Producer Application won't accept the Acknowledgment from the Kafka Server.
This kind of Acknowledgment is used when there is a need of low latency and is very fast.
Here many of messages might be loss.

ACK 1 :
-------
Whenever any message is published to the Kafka Topic,message goes to the Leader Partition.
Leader Partition writes the message to its Log file and acknowledges the Producer Application that the message has been reached to the Leader Partition.
Leader Partition then asynchronously replicate the messages to the Follower Partition based on Replication Factor.
Since the acknowledgment happens before the Follower Partition replication, 
If the leader fails immediately after sending the ACK, that message might be lost.
Here Messages are not placed at the Follower Partition.

ACK ALL or ACK -1 :
-------------------
Whenever we want the highest level of assurance that the messages has been reached to the Kafka System we use ACK ALL.
Whenever any message is published to the Topic,message goes to the Leader Partition.
Leader Partition will Replicate the messages to the Follower Partition based on Replication Factor.
Once the Replication has been done,Kafka Server will acknowledge the Producer Application that the Message has been received.
Here Messages are placed at both places i.e Leader and Follower.

B.Retry :
---------
Whenever any Producer Application is sending the message to the Kafka Server i.e. Topic and message got failed while publishing the message,
we can retry the message based on retry Configuration.

C.Throughput :
--------------
Throughput can be configured by using batch.size and batch is measured in terms of Bytes.
Throughput can be used to publish the number of messages in a particular amount of time.
Whenever Producer Application is sending the messages one by one to the Topic it will take time.
Configure the Batch size and send the messages to the Kafka Topic.
Producer Application will wait till the Batch Size reaches and will publish the messages to the Kafka Topic.
The Problem with this Approach is if the throughput is low i.e. message flow is slow in that case it won't reach the Batch Size and 
Producer Application will not publish any message to the Kafka Topic.
This can be resolved by using Linger.

D.Latency :
-----------
Latency is configured by using linger.ms
If the message flow is low for the Producer Application and we have configured the Batch Size,
In this case Producer Application will publish the messages to the Kafka Server once it reaches the Latency Time and will not wait
for the Batch Size to be reached.

E.Synchronous vs Asynchronous :
-------------------------------
Whenever we are providing any Producer Application with any Technology,
Kafka Provides an API or Functions that can send the messages in Synchronous Way or Asynchronous Way.
In case of Synchronous Communication It will wait until the response has been sent and it is a Blocking State.
Where as In Asynchronous Communication,Request will be sent in background and it will not wait for the Response.

********************************************************* 4.Consumer ***********************************************

1.Consumer group :
----------------
Whenever we are creating any Consumer Application, We need to start the consumer's so that it can read the data from Kafka Partition's.
Whenever we are starting the Consumer, we need to assign it to a Consumer Group.
In one Consumer group, there can be multiple consumers and multiple consumer's belonging to the same group can subscribe to the same topic.
Consder the scenario where we have 4 Kafka partitions

Partition 1
Partition 2
Partition 3
Partition 4

There is only one consumer i.e. Consumer1 which belongs to consumer group CG.
The consumer Consumer1 will consume the data from all the partitions.

Now created one more consumer i.e. Consumer2 within the same consumer group CG.
Now both the consumers i.e. Consumer1 and Consumer2 wll start reading the data from the same topic.
Here Kafka will rebalance the subscription among all the consumers available in the consumer group.
Means Kafka will assign 2 partitions to Consumer1 and 2 partitions to Consumer2.

Maximum no of Consumer's in the Consumer Group can be same or less than no of partitions.


2.Commmits :
------------
There are tw kind of commits
Auto Commit
Manual Commit

Auto Commit :
-------------
Consider the scenario where we have a topic named Topic1 and the consumer named Consumer1 which is consuming the messagea from Topic1.
Each message in the Kafka Topic has an offSet number.
Whenever any Consumer reads the message from Kafka Topi, then consumer marks this as read.
This can be achieved by using two properties.

	enable.auto.commit=true
	auto.commit.interval.ms=3000
	
For every 3 seconds it will commit the offset number.

Manual Commit :
---------------
Consider the scenario where the Toipc has sent the message and there is an issue in the Consumer.
In this case message is lost.
To overcome this scenario we use manual commit.
In this scenario, only after processing the message, will mark it as read and commit the offset numbers.

	enable.auto.commit=false

It will ensure that no messages are lost within the Topic and Consumer.

3.Heartbeat Interval :
----------------------
Consider the scenario where we have four partitions in the topic and 4 consumer groups.

Partition 1
Partition 2
Partition 3
Partition 4

Consumer1
Consumer2
Consumer3
Consumer4

We have the property called 

	heartbeat.interval.ms=1000
	
While reading the messages from the Partion, these Consumers will send the hear beats to Kafka Partition or Broker.
This will inform the Partition that the consumer is stil active and reading the messages from partitions.
If there is no heart beat from the consumer, Partition or Broker assumes that there is an issue in Consumer.
Then Kafka will re-balance the consumer's in the consumer group.

4.session timeout :
-------------------
Consumer will send the heart beat to the Broker.
Consider the scenario where the consumer has not sent the heart beat.
When the session will get timeout for that particular consumer i.e. When the Broker will get to know that there is an issue in consumer.
This is based on session time out property.

	session.timeout.ms=1000
	
4.Auto offset reset :
---------------------
Auot offset reset is a strategy which we need to include in the consumer to inform from where it wants to read the messages from kafka topic.

Consider the scenario where the producer has pushed the messages to the kafka topic.
Here the message count is 1001 to 1010 in the particular partition of that topic.
Now the Consumer group has 4 consumers which are ready to read the messages from the partition.
From where the consumer has to start reading the messages is decided by using auto offset reset property.

		auto.offset.reset=early
		auto.offset.reset=latest
		auto.offset.reset=none
		
earliest :
----------
Consumer will read all the messages including existing messages.

latest :
--------
Consumer will read the messages which are getting pushed to the partition after the consumer has created.

none :
------
Consumer will read the messages from the latest committed offset number which was committed by consumer.

